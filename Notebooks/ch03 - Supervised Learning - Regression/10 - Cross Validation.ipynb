{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: #C9C9C9'>Machine Learning with Python<img style=\"float: right; margin-top: 0;\" width=\"240\" src=\"../../Images/cf-logo.png\" /></h1> \n",
    "<p style='color: #C9C9C9'>&copy; Coding Fury 2022 - all rights reserved</p>\n",
    "\n",
    "<hr style='color: #C9C9C9' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "Why do we need cross-validation? \n",
    "\n",
    "* in case the test data isn't representative of the overall test\n",
    "\n",
    "\n",
    "We're going to split our data into 5 groups or \"folds\". \n",
    "\n",
    "* Fold 1 will be a test set. \n",
    "* Folds 2,3,4,5 will be used to fit our model\n",
    "* Compute the Error = either $R^2$ or MSE\n",
    "\n",
    "Then we do this 5 times in total, each time changing the test set, so that folds 1, 2, 3, 4, and 5 each get their turn at being the test set, with the data fitted on the other folds.\n",
    "\n",
    "This is 5-fold cross validation. Although the number of folds you choose is up to you. In general, we call this k-folds cross validation (k-folds CV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df = pd.read_csv('../../Data/tips.csv')\n",
    "tips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips_df['tip'].values.reshape(-1,1)  # this could have been done: happiness_df[['income']].values\n",
    "y = tips_df['total_bill'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select rows for testing\n",
    "\n",
    "Select rows based on random_state 21, and score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test) # The R^2 value for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat: Selecting different Rows for testing\n",
    "\n",
    "Select rows based on random_state 1, and score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test) # The R^2 value for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion - There's a problem\n",
    "\n",
    "As we've seen above, the accuracy of a model can vary quite a bit depending on how we split our data into training and test. \n",
    "\n",
    "The problem can be exaggerated if the training data has been sorted in Excel. \n",
    "\n",
    "E.g. Perhaps the training data was sorted by target value (using Excel) before we read it in? The training dataset would contain the smaller values, and the test set would contain larger values.  \n",
    "\n",
    "Even if the training data is organised randomly, there's still a risk that bias can be introduced unintentionally.\n",
    "\n",
    "\n",
    "# Solution - Cross Validation!\n",
    "\n",
    "The solution to our problem is to perform cross validation. \n",
    "\n",
    "There are a few different approaches to Cross Validation, this type of Cross Validation is called \"Kfolds Cross Validation\". \n",
    "\n",
    "In cross validation, the data is split into k folds. For the purposes of this example, we'll set k=5 (5 folds)\n",
    "* Imagine that have 1000 rows of data (1000 observations). \n",
    "* We split the data into 5 Folds. Each time the training set will be 800 rows, and the test set wil be $\\frac{1000} {5} = 200$ rows\n",
    "* using cross validation we then train and test the model on each of the 5-folds in turn\n",
    "\n",
    "![K Folds](../../Images/kfolds.png)\n",
    "\n",
    "The advantage of KFolds is that the entire dataset is used for training the model. Using this method, we can the calculate accuracy as an average across all the individual folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = LinearRegression()\n",
    "cv_results = cross_val_score(model, X, y, cv=kf) \n",
    "cv_results # R^2 is the default way to measure accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean and standard deviation of $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(cv_results), np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(cv_results, [0.025, 0.975])) # The 95% confidence interval of R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the min and max $R^2$ for the 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(cv_results), np.max(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Discuss: \n",
    "* what are your thoughts on Cross Validation in general?\n",
    "* what are your thoughts on Cross Validation as applied to this particular dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
