{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d6a8ef-64a4-42d0-bcaa-7a588ad8abb7",
   "metadata": {},
   "source": [
    "<h1 style='color: #C9C9C9'>Machine Learning with Python<img style=\"float: right; margin-top: 0;\" width=\"240\" src=\"../../Images/cf-logo.png\" /></h1> \n",
    "<p style='color: #C9C9C9'>&copy; Coding Fury 2022 - all rights reserved</p>\n",
    "\n",
    "<hr style='color: #C9C9C9' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788da1e7",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "## The Iris Dataset\n",
    "\n",
    "![Iris Flowers](../../Images/iris-machinelearning.png)\n",
    "\n",
    "The Iris Dataset provides 4 measurements from each iris flower: \n",
    "- Petal length and width\n",
    "- Sepal length and width\n",
    "\n",
    "Based on these 4 variables, it should be possible to predict which of 3 varieties any given iris flower is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba28c-c0e8-4363-8468-4b07981805de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification with k-Nearest Neighbors\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "Note that you will choose a value for k. In the case of the iris dataset, the flowers are grouped into 3 classes, so k=3.\n",
    "* Any new data point will be assigned a category based on the 3 closest data points in the training set.\n",
    "* knn uses a majority vote to determine which category to put the new point into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8acc9-2392-4c39-a62c-c276e611cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f03fd-b507-4cd9-9601-117dd2fc0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"../../Data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699fcd7-7c77-4f44-9d55-d4654a4846db",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c5b10-442d-438d-b865-420e0cd4db6c",
   "metadata": {},
   "source": [
    "# Initial Look\n",
    "\n",
    "Let's have an initial look at the data to see if the \"features\" we have can be used to determine the species of iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112df60-06ac-42ad-80b1-5bac6cc112f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc0385",
   "metadata": {},
   "source": [
    "**Note**\n",
    "* no missing values in any columns\n",
    "* however the species is a string and we SciKit Learn can only work with numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134c5a8-e0ac-46ba-bb55-033c0ec06883",
   "metadata": {},
   "source": [
    "## We need the Species to be numerical for charting - convert it to a Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d9d66-3495-45ba-be43-d8a4d508b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df[\"Category\"] = iris_df[\"Species\"].astype(\"category\") # a category is a bit like an enum in programming. It's numerical under the hood\n",
    "                                                            # We could also have used SciKit Learn's LabelEncoder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b4734-717c-44e0-9d11-03bdd0ef993f",
   "metadata": {},
   "source": [
    "## Do Sepal measurements help when predicting species? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666990c-c53d-4b31-8357-04533c8b4806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489145b6-75b7-4e1f-aa56-5de86e64b3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", data=iris_df, hue='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5ceaa-6afe-4380-9177-00379e69118d",
   "metadata": {},
   "source": [
    "ColorMaps: https://matplotlib.org/stable/gallery/color/colormap_reference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0db08d-77f5-4117-aeb6-59ee4b666c49",
   "metadata": {},
   "source": [
    "### No, not really\n",
    "\n",
    "## Do Petal measurements help when predicting species? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503a1f7-8e44-41d8-8761-e117937a68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"PetalLengthCm\", y=\"PetalWidthCm\", data=iris_df, hue='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd6be2-b031-4a18-89e6-e90cb7327b4e",
   "metadata": {},
   "source": [
    "### Yes! We can work with that!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee5bb9-d4ba-4264-92dd-e621ae0804db",
   "metadata": {},
   "source": [
    "# Train the kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67769a7e-50dc-46a7-acb9-53055a980237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c72a9-6c58-4d4a-a7b7-747940a06aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"PetalLengthCm\",\"PetalWidthCm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2e7e0-3717-404d-a752-659cfaad3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df[features].values # this is the contents of the column as a numpy array\n",
    "y = iris_df[\"Species\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541429a-2de4-49ff-a4d8-d30f1624da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fa4c1-0ff5-45b5-8346-8a3ab7542887",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dae4e7-3327-435e-964f-e807f859bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950dc3ee",
   "metadata": {},
   "source": [
    "Make up some new values for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2d83c-9845-429e-a1cf-3a9a500a5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([\n",
    "    [2,0.2],\n",
    "    [1.4,0.3],\n",
    "    [3.9,3.7],\n",
    "    [4.6, 1.4]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12896e0-1128-40d0-a1a2-2e4e452115ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee052425-9b6a-4413-85c4-0d12b712b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82304333-e7bd-48b4-96b5-b83c4b61033e",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# How good is our model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35123336-6ece-4f17-9be5-22f4b50ba1b8",
   "metadata": {},
   "source": [
    "## Measuring Model Performance\n",
    "\n",
    "In order to measure the performance of our model we need to: \n",
    "\n",
    "1. Get some data that's not part of our training set, for which we know the target value.\n",
    "2. The easiest way to achieve this is to split our dataset in two parts. We'll use 70% of it for training, and we'll withhold 30% for testing.\n",
    "3. Measure how well our predictions fared against the correct answer, by calculating the accuracy.\n",
    "\n",
    "$$ accuracy = \\frac{correct \\space predictions}{total \\space observations} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b734325-98a3-437c-8c44-868151b92498",
   "metadata": {},
   "source": [
    "## Splitting data into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83a82c-1393-46db-b272-dda40b2ac186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370d638-6862-4aae-bef1-f623c9a6c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776cea55-0738-4e48-a7a6-99d7ccc2be7c",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "```test_size=0.3``` \n",
    "\n",
    "> This sets 30% of our data as test set i.e. 70% will be used to train our model\n",
    "\n",
    "```random_state=21```\n",
    "\n",
    "> This is a seed for a random number generator that splits the data i.e. test rows are selected at random based on the seed. \n",
    ">  Choosing the same number will guarantee the same rows are selected for the split each time, making our program repeatable, with the same rows in the training and test set each time.\n",
    "\n",
    "```stratify=y```\n",
    "\n",
    "> This guarantees that proportion of rows that have setosa, virginica and versicolor are the same in both the training and test data sets. \n",
    "\n",
    "**RETURENED VALUES**\n",
    "\n",
    "The data is returned as a tuple that contains 4 variales\n",
    "\n",
    "```X_train``` \n",
    "> this is the training data\n",
    "\n",
    "```X_test```\n",
    "> this is the test data\n",
    "\n",
    "```y_train```\n",
    "> the traing data labels labels (in this case the species)\n",
    "\n",
    "```y_test```\n",
    "> the test data labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a965a-69cd-4b61-9dc7-c4c10352dfb2",
   "metadata": {},
   "source": [
    "## Calculating the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99814e4-f308-49b9-b3e3-cd91a0050112",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a270d-0701-4257-a00d-e5f1b2231041",
   "metadata": {},
   "source": [
    "Our accuracy is therefore 97.8%, which is high, but could we have done better?\n",
    "\n",
    "Can you improve the accuracy by changing the value of ```n_neighbors```? Try different values. Start with 3, and gradually increase the number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8052f96-f2c1-48e9-8c4c-945a7a138284",
   "metadata": {},
   "source": [
    "\n",
    "k is large\n",
    "* less complex model\n",
    "* new observations are compared against a large number of neighbors\n",
    "* can cause underfitting\n",
    "\n",
    "k is small \n",
    "* more complex model \n",
    "* new observations are compared against a small number of neighbors\n",
    "* can cause overfitting i.e. one erroneous value could strongly impact a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55826524-9544-4f77-80d9-a0659a78ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "neighbors = np.arange(1,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab010d18-b0d5-4c02-9f95-6d3f3dabdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_accuracies[neighbor] = knn.score(X_train, y_train)\n",
    "    test_accuracies[neighbor] = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f4f54-73fc-4ff7-a421-db420e8f223c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07929535-0c31-44e9-8be8-4850c88cf98c",
   "metadata": {},
   "source": [
    "## Plotting the accuracy for each value of n_neighbors\n",
    "\n",
    "## Model Complexity Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a30d2d-ca88-4429-8b07-39cb072a199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"KNN\")\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c976e-ea3b-4182-beea-ce6fb34575e0",
   "metadata": {},
   "source": [
    "For this dataset most the values of n_neighbors offer a good fit. \n",
    "\n",
    "The peak test accuracy occurs at neighbours=4\n",
    "\n",
    "Ideally the Training data should be a better fit than the test data, so this indicates that our sample size of 150 records probably isn't big enough. \n",
    "\n",
    "An example of the kind of chart we would expect to see is shown below\n",
    "\n",
    "![Model Complexity Curve](../../Images/knn-model-complexity-curve.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c315c0-ce71-4d85-951d-d3c765e2a637",
   "metadata": {},
   "source": [
    "# Plot decision boundaries\n",
    "\n",
    "To plot Desicion boundaries you need to make a meshgrid. You can use np.meshgrid to do this. np.meshgrid requires min and max values of X and Y and a meshstep size parameter. It is sometimes prudent to make the minimal values a bit lower then the minimal value of x and y and the max value a bit higher.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f805a19-dc18-4904-8c87-6c3ef4ebd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ea88b-6125-4b82-8fff-b3ec4c9672af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959617bf-2596-4c45-8fc6-0aa2d15f06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                 np.arange(y_min, y_max, h))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cafae-aa59-4337-a155-90543a589591",
   "metadata": {},
   "source": [
    "You then feed your classifier your meshgrid like so ```Z=knn.predict(np.c_[xx.ravel(), yy.ravel()])```\n",
    "\n",
    "You need to reshape the output of this to be the same format as your original meshgrid \n",
    "\n",
    "```Z = Z.reshape(xx.shape)```\n",
    "\n",
    "Finally when you are making your plot you need to call ```plt.pcolormesh(xx, yy, Z, cmap=cmap_light)``` \n",
    "\n",
    "This will make the decision boundaries visible in your plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4700203-5622-4271-906d-417a09a45e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color maps\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16278208-21ed-4310-8eaa-b441018c89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9169647-b31b-464e-b595-10a4afe9bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"PetalLengthCm\",\"PetalWidthCm\"]\n",
    "X = iris_df[features].values # this is the contents of the column as a numpy array\n",
    "y = iris_df[\"Category\"].cat.codes  # the numerical value of each category\n",
    "\n",
    "neighbors = 5\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbors, weights=weights)\n",
    "    knn.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.rcParams['pcolor.shading'] ='nearest'\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(f\"3-Class classification (k = {neighbors}, weights = {weights})\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58257a-f59a-440e-8ed4-3ca018ec1c6c",
   "metadata": {},
   "source": [
    "The above example used code taken from: \n",
    "https://scikit-learn.org/stable/auto_examples/neighbors/plot_nca_classification.html#sphx-glr-auto-examples-neighbors-plot-nca-classification-py\n",
    "\n",
    "\n",
    "# Next steps\n",
    "\n",
    "Try different Classifiers on this dataset\n",
    "\n",
    "Original: https://towardsdatascience.com/exploring-classifiers-with-python-scikit-learn-iris-dataset-2bcb490d2e1b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6da3c-d491-4ad9-8791-6bda57b4f7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
