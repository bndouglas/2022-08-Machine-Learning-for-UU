{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: #C9C9C9'>Machine Learning with Python<img style=\"float: right; margin-top: 0;\" width=\"240\" src=\"../../Images/cf-logo.png\" /></h1> \n",
    "<p style='color: #C9C9C9'>&copy; Coding Fury 2022 - all rights reserved</p>\n",
    "\n",
    "<hr style='color: #C9C9C9' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "In this example we're going to load in the James Bond Dataset. \n",
    "\n",
    "The target variable will to determine if the movie makes it into the IMDB Top_100. We'll therefore be using Logistic Regression. \n",
    "\n",
    "Before training our model we'll need to preprocess our data with 2 transformers: \n",
    "* we'll use SimpleImputer to insert missing values (in reality there aren't any, but please play along!)\n",
    "* we'll use StandardScaler to scale and centre our data (standardisation)\n",
    "\n",
    "In order to do this we'll build a pipeline with 3 steps: \n",
    "1. Impute - insert missing values\n",
    "2. Standardise - i.e. scale and centre our data\n",
    "3. Train a Logistic Regression Model\n",
    "\n",
    "Note that Pipelines can have multiple steps that transform the data, but you can only train a single model - in this case we'll be using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df = pd.read_csv('../../Data/JamesBond.csv')\n",
    "bond_df = bond_df.drop('Movie', axis=1)\n",
    "bond_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep this simple let's drop the Bond column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df = bond_df.drop('Bond', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bond_df.drop('Top_100', axis=1).values\n",
    "y = bond_df['Top_100'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent', missing_values=np.NaN)), \n",
    "            ('scaler', StandardScaler()), \n",
    "            ('model', LogisticRegression())\n",
    "            ])\n",
    "# There aren't any missing values, so we don't actually need the Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Now we can make a prediction for a movie we're going to make in 2030. \n",
    "\n",
    "My prediction is actually just the same data as the most recent movie made in 2015. So I guess my question is do we need to increase the budget for the next movie. \n",
    "\n",
    "Arguably we should really get rid of the World and US grossing columns as these really aren't input columns. But the aim here is to keep the example simple and focus on how Pipelines work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "newX = np.array([[2030,200074175,196647,879620923,864553,245000,240803,148,6.8,6.4,3,1,1,30,205]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray, we've made it into the Top 100!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Train and Test\n",
    "\n",
    "One of the main benefits of building a pipeline is repeatability. \n",
    "\n",
    "Using a pipeline it's super-easy to apply the same steps to your training dataset and your test dataset.\n",
    "\n",
    "Note that it's important that some Tranformers e.g. StandardScaler is run separately on Training and Test, to simulate how the model would perform in new data in production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
