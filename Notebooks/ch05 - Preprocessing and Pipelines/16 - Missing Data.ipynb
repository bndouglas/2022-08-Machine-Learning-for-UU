{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: #C9C9C9'>Machine Learning with Python<img style=\"float: right; margin-top: 0;\" width=\"240\" src=\"../../Images/cf-logo.png\" /></h1> \n",
    "<p style='color: #C9C9C9'>&copy; Coding Fury 2022 - all rights reserved</p>\n",
    "\n",
    "<hr style='color: #C9C9C9' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data\n",
    "\n",
    "As you'll recall SciKit Learn mandates that the input dataset cannot contain missing data. In this tutorial, we're going to use the Automobiles dataset which doesn't meet this critera.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Automobiles Dataset \n",
    "\n",
    "Start by loading the data, and examining it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "auto_df = pd.read_csv('../../Data/automobiles.csv')\n",
    "auto_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that not all columns of data are shown (the missing columns are between wheel_base and engine_size)\n",
    "\n",
    "Let's tell Pandas to show all columns when displaying the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "auto_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll examine which columns are missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we're missing some columns so let's make sure we're seeing data about all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.iloc[:, 0:20].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df.iloc[:, 20:].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy 1: Deleting columns with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst column for missing is the normalised_losses column which only has data for 164 observations.\n",
    "\n",
    "As it happens the symboling and normalised losses relate to predicting insurance premiums, so we can drop the first 2 columns. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = auto_df.drop(['symboling', 'normalised_losses'], axis=1)\n",
    "auto_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy 2: Finding Rows of Missing Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below finds rows that have a missing value in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_missing = auto_df.isna().any(axis=1)\n",
    "auto_df[flt_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_missing = auto_df.isna().any(axis=1)\n",
    "auto_df[flt_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy 3: Deleting Rows\n",
    "\n",
    "A common approach is to remove missing data. Generally speaking this is OK so long as it's less than 5% of the overall data. \n",
    "\n",
    "In this dataset the target variable will be price. \n",
    "\n",
    "Let's delete the rows that have no price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the rows that are missing values for price\n",
    "flt_missing = auto_df['price'].isna()\n",
    "auto_df[flt_missing==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = auto_df.dropna(subset=['price'])  # the subset contains a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df  # note that we're down to 201 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "\n",
    "This leaves us with 8 rows that have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_missing = auto_df.isna().any(axis=1)\n",
    "auto_df[flt_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy 4: Imputing Data\n",
    "\n",
    "## 4a - Imputing using dropna and fillna\n",
    "\n",
    "Imputing data means replacing a missing value with a value that seems reasonable. \n",
    "\n",
    "Imagine that we survey a class of year 13 students to find out what their age is. \n",
    "\n",
    "Of the 10 students in the class, only 8 responded. \n",
    "\n",
    "| #  | Student | Age |\n",
    "| -- | ------- | --- |\n",
    "| 1  | Anne    | 16  |\n",
    "| 2  | Brian   | 17  |\n",
    "| 3  | Claire  | 16  |\n",
    "| 4  | David   | 17  |\n",
    "| 5  | Ellen   |     |\n",
    "| 6  | Fred    |     |\n",
    "| 7  | Gwen    | 16  |\n",
    "| 8  | Harry   | 17  |\n",
    "| 9  | Ian     | 16  |\n",
    "| 10 | Julie   | 17  |\n",
    "\n",
    "Let's calculate the average age of the students\n",
    "\n",
    "$$ \\frac{16+17+16+17+16+17+16+17}{10} = 13.2 $$\n",
    "\n",
    "Clearly there's something wrong here, because there are no students aged 13 in year 13! \n",
    "\n",
    "With an equal number of students aged 16 and 17, common sense would tell you that the average age of the students should have been 16.5.\n",
    "\n",
    "The mistake that we made was to divide by 10. Because we only have ages for 8 of the 10 students we probably should have divided by 8. \n",
    "\n",
    "$$ \\frac{16+17+16+17+16+17+16+17}{8} = 16.5 $$\n",
    "\n",
    "Effectively this is the same as deleting the empty rows; like we did in Strategy 3, above. \n",
    "\n",
    "Other strategies we could have used would have been to replace the missing values with a value that seems reasonable.\n",
    "\n",
    "For example, blank values could be substituted with: \n",
    "\n",
    "* zero \n",
    "  * in some cases, zero is the correct number to substitute. Know your data!\n",
    "* mean \n",
    "  * the average of the numbers that do have values - in the example above this would be 16.5\n",
    "* median\n",
    "  * this is the central number. In a frequency distribution, there's a 50/50 chance of any point being higher or lower than this number. \n",
    "* mode \n",
    "  * most frequently appearing number in the dataset. Sometimes it's appropriate to substitute missing numbers with the number that it's statistically most likely to be.\n",
    "\n",
    "Let's consider how this would work in our class of Year 13 students. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Student': ['Anne', 'Brian', 'Claire', 'David', 'Ellen', 'Fred', 'Gwen', 'Harry', 'Ian', 'Julie'],\n",
    "'Age': [16, 17, 16, 17, np.NaN,np.NaN , 16, 17, 16, 17] \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that np.NaN stands for \"Not a Number\"\n",
    "* This is the same as a null i.e. you're explicitly saying \"there's nothing here\"\n",
    "\n",
    "Let's make our data_dict into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = pd.DataFrame(data = data_dict)\n",
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df.fillna(0)  #With this command we can fill all missing values with a 0 - this is applied across all columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we didn't actually save the new values (by now, I expect you know how to do this). \n",
    "\n",
    "fillna() can also be applied to a single column rather than a whole dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df['Age'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to fill the missing data with the mean, median or mode? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df['Age'].fillna(students_df['Age'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df['Age'].fillna(students_df['Age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example the median is the same value as the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df['Age'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Mode always returns a Pandas Series. In this case there's a tie, so the Pandas Series contains more than one value.\n",
    "\n",
    "We can get the first number from this Series with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df['Age'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check if there are one or more values that occur most frequently with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(students_df['Age'].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's fill the missing ages with the mode (or at least the first value that comes back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df['Age'].fillna(students_df['Age'].mode()[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing if mean, median or mode is most suitable, requires knowing your data and also what you're trying to achieve. \n",
    "\n",
    "The diagram below illustrates how mean, median and mode differ depending on if your data are skewed to one side or another.\n",
    "\n",
    "![Mean Median Mode](../../Images/wikipedia-mean-median-mode-skew.png)\n",
    "\n",
    "Image source: https://en.wikipedia.org/wiki/Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_missing = auto_df.isna().any(axis=1)\n",
    "auto_df[flt_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply what we learned to the auto_df data frame.\n",
    "\n",
    "1. Replace missing values in the 'num_of_doors' column with the mode (yes, it will work on a text column!)\n",
    "2. Replace missing values for 'bore' and 'stroke' with the mean\n",
    "3. Replace missing values for 'horsepower' and 'peak_rpm' with the median\n",
    "\n",
    "\n",
    "Note that on the Latest version of Python, I've recently encountered warnings when performing these tasks. \n",
    "\n",
    "If you encounter a warning that says \"SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\" Just ignore it (assuming your code works).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = auto_df['num_of_doors'].mode()\n",
    "mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['num_of_doors'].fillna(mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['num_of_doors'] = auto_df['num_of_doors'].fillna(mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['bore'].fillna(auto_df['bore'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['stroke'] = auto_df['stroke'].fillna(auto_df['stroke'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['horsepower'] = auto_df['horsepower'].fillna(auto_df['horsepower'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df['peak_rpm'] = auto_df['peak_rpm'].fillna(auto_df['peak_rpm'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense? Who knows! Remember this is just a tutorial, so I want to use a range of techniques. \n",
    "\n",
    "In an ideal world, I'd be able to hunt down the missing data, and get the correct values. \n",
    "\n",
    "After that, it's up to you to discern what the best trade-offs are. For sure, we're better to use the mean and median, than zeros in this dataset. But would we have been better just to delete the rows with missing data? \n",
    "\n",
    "Perhaps a little domain knowledge could be useful? Or maybe you'll try training your model with and without imputed data to see how it performs in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check that we haven't left any missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_missing = auto_df.isna().any(axis=1)\n",
    "auto_df[flt_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
